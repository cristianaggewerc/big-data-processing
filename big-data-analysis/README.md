# Big Data Processing, Analysis and Visualisation	

## Description

   1) `Analysing Text Data.ipynb`

   Analysis of two books on software development methodologies. We will see the distribution of words, the most common words in both books and the average frequency. 

   The steps consist of: importing `pyspark` and initializing Spark, creating Resilient Distributed Datasets (RDDs), cleaning/manipulating text, transforming the cata/counting the words, removing Stop Words, finding the average occurrence of a word and exploratory data analysis. 

![Imgur](https://i.imgur.com/p9uCKc3.png)

   2) `Analysing CSV Data.ipynb`

   Analysis of crime data from South Australia. 

   Here we work with `MongoDB` and Spark DataFrames.

![Imgur](https://i.imgur.com/3x6xWL7.png)

## Data
- `Agile Processes in Software Engineering and Extreme Programming.txt`: Book1
- `Scrum Handbook.txt`: Book2
- `Crime_Statistics_SA_2010_present.csv`: The dataset reflects reported incidents of crime (suburb-based crime statistics for crimes against the person and crimes against property.) that occurred in South Australia since 2010.